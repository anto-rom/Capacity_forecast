{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a3a4968",
   "metadata": {},
   "source": [
    "\n",
    "# corporate_hybrid_forecast_v17_2\n",
    "\n",
    "This notebook replaces the baseline forecaster with the **recommended model per department**, applies **bias-based calibration**,\n",
    "and exports monthly results including the **Board_[department]_2627** sheets and a **Model_Used_and_Error** summary.\n",
    "\n",
    "Pipeline: daily forecast → monthly (sum) → Einstein deduction → bias-based calibration → capacity projection → executive boards.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95eba70",
   "metadata": {},
   "source": [
    "## 1) Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c67eb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT_XLSX → C:\\Users\\pt3canro\\Desktop\\CAPACITY\\outputs\\capacity_forecast_v17_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from calendar import monthrange\n",
    "\n",
    "BASE_DIR = r'C:\\Users\\pt3canro\\Desktop\\CAPACITY'\n",
    "BASE_DIR = str(Path(BASE_DIR).expanduser().resolve())\n",
    "\n",
    "INPUT_DIR  = str(Path(BASE_DIR) / 'input_model')\n",
    "OUTPUT_DIR = str(Path(BASE_DIR) / 'outputs')\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INCOMING_SOURCE_PATH = os.path.join(INPUT_DIR, 'Incoming_new.xlsx')\n",
    "INCOMING_SHEET       = 'Main'\n",
    "DEPT_MAP_PATH  = os.path.join(INPUT_DIR, 'department.xlsx')\n",
    "DEPT_MAP_SHEET = 'map'\n",
    "AGENT_CAPACITY_PATH = os.path.join(INPUT_DIR, 'agent_language_n_target.xlsx')\n",
    "EINSTEIN_PATH       = os.path.join(INPUT_DIR, 'einstein.xlsx')\n",
    "INVENTORY_PATH      = os.path.join(INPUT_DIR, 'inventory_month.xlsx')\n",
    "\n",
    "OUTPUT_XLSX = os.path.join(OUTPUT_DIR, 'capacity_forecast_v17_2.xlsx')\n",
    "\n",
    "HORIZON_MONTHS = 12\n",
    "VERTICALS_TARGET = ['Payments','Partners','Hospitality']\n",
    "TARGET_TPH = 6.0\n",
    "EXCLUDE_DEPARTMENT_NAME_TOKENS = ['PROJ','DIST','KEY','PROXIMIS']\n",
    "\n",
    "print('OUTPUT_XLSX →', OUTPUT_XLSX)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628abbe9",
   "metadata": {},
   "source": [
    "## 2) Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bda7a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick first present column name\n",
    "def pick_col(df, candidates):\n",
    "    for c in candidates:\n",
    "        if c in df.columns:\n",
    "            return c\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "    for c in candidates:\n",
    "        if c.lower() in lower:\n",
    "            return lower[c.lower()]\n",
    "    return None\n",
    "\n",
    "def std_cols(df):\n",
    "    df.columns = [c.strip() for c in df.columns]\n",
    "    return df\n",
    "\n",
    "def to_month_start(dt_series):\n",
    "    s = pd.to_datetime(dt_series, errors='coerce')\n",
    "    return s.dt.to_period('M').dt.to_timestamp(how='start')\n",
    "\n",
    "def working_days_in_month(year:int, month:int):\n",
    "    start = datetime(year, month, 1)\n",
    "    end = datetime(year+1,1,1)-timedelta(days=1) if month==12 else datetime(year,month+1,1)-timedelta(days=1)\n",
    "    days = pd.date_range(start, end, freq='D')\n",
    "    return int(np.sum(days.dayofweek < 5))\n",
    "\n",
    "def validate_quantiles(dfm):\n",
    "    viol = dfm[(dfm['forecast_p05_dept']>dfm['forecast_monthly_dept']) | (dfm['forecast_monthly_dept']>dfm['forecast_p95_dept'])]\n",
    "    if not viol.empty:\n",
    "        raise ValueError('Quantile order violation in monthly aggregation.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d89a7bc",
   "metadata": {},
   "source": [
    "## 3) Forecast engines (Baseline/STL + SARIMAX-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6703b30a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def forecast_daily_baseline(y: pd.Series, horizon_days: int = 365):\n",
    "    y = y.asfreq('D').fillna(0)\n",
    "    if len(y) < 56:\n",
    "        idx = pd.date_range(y.index[-1] + pd.Timedelta(days=1), periods=horizon_days, freq='D')\n",
    "        last_week = y[-7:].to_numpy()\n",
    "        p50 = np.resize(last_week, horizon_days)\n",
    "        resid = (y[7:] - y.shift(7)[7:]).dropna()\n",
    "        std = resid.std() if len(resid)>0 else max(1.0, np.sqrt(max(y.mean(),1)))\n",
    "        p05 = np.clip(p50 - 1.645*std, 0, None)\n",
    "        p95 = p50 + 1.645*std\n",
    "        return pd.DataFrame({'date': idx, 'p50': p50, 'p05': p05, 'p95': p95})\n",
    "    try:\n",
    "        from statsmodels.tsa.seasonal import STL\n",
    "        y_box = np.log1p(y)\n",
    "        stl = STL(y_box, period=7, robust=True)\n",
    "        res = stl.fit()\n",
    "        trend, seas, resid = res.trend, res.seasonal, res.resid\n",
    "        last_trend = trend.iloc[-1]\n",
    "        std = resid.std() if resid.std()>0 else 0.5\n",
    "        idx = pd.date_range(y.index[-1] + pd.Timedelta(days=1), periods=horizon_days, freq='D')\n",
    "        seas_fut = np.resize(seas[-7:].to_numpy(), horizon_days)\n",
    "        mu_log = last_trend + seas_fut\n",
    "        p50 = np.expm1(mu_log); p50 = np.clip(p50, 0, None)\n",
    "        p05 = np.expm1(mu_log - 1.645*std); p05 = np.clip(p05, 0, None)\n",
    "        p95 = np.expm1(mu_log + 1.645*std)\n",
    "        return pd.DataFrame({'date': idx, 'p50': p50, 'p05': p05, 'p95': p95})\n",
    "    except Exception:\n",
    "        idx = pd.date_range(y.index[-1] + pd.Timedelta(days=1), periods=horizon_days, freq='D')\n",
    "        last_week = y[-7:].to_numpy()\n",
    "        p50 = np.resize(last_week, horizon_days)\n",
    "        resid = (y[7:] - y.shift(7)[7:]).dropna()\n",
    "        std = resid.std() if len(resid)>0 else max(1.0, np.sqrt(max(y.mean(),1)))\n",
    "        p05 = np.clip(p50 - 1.645*std, 0, None)\n",
    "        p95 = p50 + 1.645*std\n",
    "        return pd.DataFrame({'date': idx, 'p50': p50, 'p05': p05, 'p95': p95})\n",
    "\n",
    "\n",
    "def forecast_daily_sarimax(y: pd.Series, horizon_days: int = 365):\n",
    "    try:\n",
    "        from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "    except Exception:\n",
    "        return None\n",
    "    y = y.asfreq('D').fillna(0)\n",
    "    y_log = np.log1p(y)\n",
    "    try:\n",
    "        model = SARIMAX(y_log, order=(1,0,1), seasonal_order=(1,0,1,7), enforce_stationarity=False, enforce_invertibility=False)\n",
    "        res = model.fit(disp=False)\n",
    "        pred = res.get_forecast(steps=horizon_days)\n",
    "        mean = np.expm1(pred.predicted_mean).clip(lower=0)\n",
    "        resid = (y[7:] - y.shift(7)[7:]).dropna()\n",
    "        std = resid.std() if len(resid)>0 else 1.0\n",
    "        p05 = np.clip(mean - 1.645*std, 0, None)\n",
    "        p95 = mean + 1.645*std\n",
    "        idx = pd.date_range(y.index[-1] + pd.Timedelta(days=1), periods=horizon_days, freq='D')\n",
    "        return pd.DataFrame({'date': idx, 'p50': mean.values, 'p05': p05.values, 'p95': p95.values})\n",
    "    except Exception:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a303876",
   "metadata": {},
   "source": [
    "## 4) Load inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d9b90cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "incoming_raw = pd.read_excel(INCOMING_SOURCE_PATH, sheet_name=INCOMING_SHEET, engine='openpyxl')\n",
    "std_cols(incoming_raw)\n",
    "\n",
    "c_date = pick_col(incoming_raw, ['Date','date'])\n",
    "c_dept = pick_col(incoming_raw, ['department_id','dept_id','Department_ID'])\n",
    "c_cnt  = pick_col(incoming_raw, ['ticket_total','Ticket_Total','count','tickets','qty'])\n",
    "if c_date is None or c_dept is None:\n",
    "    raise KeyError('Incoming_new.xlsx must include Date and department_id columns.')\n",
    "\n",
    "incoming = incoming_raw[[c_date, c_dept] + ([c_cnt] if c_cnt else [])].copy()\n",
    "incoming.columns = ['date','department_id'] + (['ticket_total'] if c_cnt else [])\n",
    "if 'ticket_total' not in incoming.columns:\n",
    "    incoming['ticket_total'] = 1\n",
    "\n",
    "incoming['date']  = pd.to_datetime(incoming['date'], errors='coerce')\n",
    "incoming['month'] = to_month_start(incoming['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "642d2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded incoming rows = 458599\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dept_map = pd.read_excel(DEPT_MAP_PATH, sheet_name=DEPT_MAP_SHEET, engine='openpyxl')\n",
    "std_cols(dept_map)\n",
    "dm_id   = pick_col(dept_map, ['department_id','dept_id','Department_ID'])\n",
    "dm_name = pick_col(dept_map, ['department_name','Department','dept_name','Department_Name'])\n",
    "dm_vert = pick_col(dept_map, ['vertical','Vertical'])\n",
    "if dm_id is None or dm_name is None or dm_vert is None:\n",
    "    raise KeyError('department.xlsx must contain department_id, department_name and vertical (sheet map).')\n",
    "\n",
    "dept_map = dept_map[[dm_id, dm_name, dm_vert]].drop_duplicates()\n",
    "dept_map.columns = ['department_id','department_name','vertical']\n",
    "\n",
    "incoming['department_id'] = pd.to_numeric(incoming['department_id'], errors='coerce').astype('Int64')\n",
    "dept_map['department_id'] = pd.to_numeric(dept_map['department_id'], errors='coerce').astype('Int64')\n",
    "\n",
    "incoming = incoming.merge(dept_map, on='department_id', how='left')\n",
    "\n",
    "# scope & exclusions\n",
    "incoming = incoming[incoming['vertical'].isin(VERTICALS_TARGET)].copy()\n",
    "mask_excl = pd.Series(False, index=incoming.index)\n",
    "for tok in EXCLUDE_DEPARTMENT_NAME_TOKENS:\n",
    "    mask_excl |= incoming['department_name'].astype(str).str.upper().str.contains(tok.upper(), na=False)\n",
    "\n",
    "incoming = incoming.loc[~mask_excl].copy()\n",
    "\n",
    "# monthly actuals\n",
    "monthly_actuals = (incoming\n",
    "                   .groupby(['vertical','department_id','department_name','month'], as_index=False)\n",
    "                   .agg(actual_volume=('ticket_total','sum')))\n",
    "print('Loaded incoming rows =', len(incoming))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad8bdada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einstein\n",
    "if Path(EINSTEIN_PATH).exists():\n",
    "    ein = pd.read_excel(EINSTEIN_PATH, engine='openpyxl'); std_cols(ein)\n",
    "    e_date = pick_col(ein, ['Date','date']); e_dept = pick_col(ein, ['department_id','dept_id','Department_ID'])\n",
    "    if e_date and e_dept:\n",
    "        ein_use = ein[[e_date, e_dept]].copy(); ein_use.columns=['date','department_id']\n",
    "        ein_use['date'] = pd.to_datetime(ein_use['date'], errors='coerce'); ein_use['month'] = to_month_start(ein_use['date'])\n",
    "        ein_month = ein_use.groupby(['department_id','month'], as_index=False).size().rename(columns={'size':'einstein_solved'})\n",
    "    else:\n",
    "        ein_month = pd.DataFrame(columns=['department_id','month','einstein_solved'])\n",
    "else:\n",
    "    ein_month = pd.DataFrame(columns=['department_id','month','einstein_solved'])\n",
    "\n",
    "# Capacity\n",
    "if Path(AGENT_CAPACITY_PATH).exists():\n",
    "    cap = pd.read_excel(AGENT_CAPACITY_PATH, engine='openpyxl'); std_cols(cap)\n",
    "    c_year  = pick_col(cap, ['Year','year'])\n",
    "    c_mnum  = pick_col(cap, ['Month_number','month_number','month'])\n",
    "    c_mstart= pick_col(cap, ['MonthStartDate','monthstartdate'])\n",
    "    c_deptc = pick_col(cap, ['department_id','dept_id','Department_ID'])\n",
    "    c_prod_total = pick_col(cap, ['productivity_total','prod_total_model'])\n",
    "    c_avgpd      = pick_col(cap, ['avg_per_day'])\n",
    "    c_hours      = pick_col(cap, ['productive'])\n",
    "    if c_mstart is None and (c_year is not None and c_mnum is not None):\n",
    "        cap['MonthStartDate'] = pd.to_datetime(cap[c_year].astype(str)+'-'+cap[c_mnum].astype(str)+'-01'); c_mstart='MonthStartDate'\n",
    "    if c_mstart is None or c_deptc is None:\n",
    "        monthly_capacity_hist = pd.DataFrame(columns=['department_id','month','capacity'])\n",
    "    else:\n",
    "        cols=[c_mstart,c_deptc]; ren={c_mstart:'month', c_deptc:'department_id'}\n",
    "        if c_prod_total: cols.append(c_prod_total); ren[c_prod_total]='tickets_capacity'\n",
    "        if c_avgpd:      cols.append(c_avgpd);      ren[c_avgpd]='avg_per_day'\n",
    "        if c_hours:      cols.append(c_hours);      ren[c_hours]='productive_hours'\n",
    "        cap_use = cap[cols].rename(columns=ren)\n",
    "        cap_use['month'] = pd.to_datetime(cap_use['month'], errors='coerce').dt.to_period('M').dt.to_timestamp(how='start')\n",
    "        if 'tickets_capacity' in cap_use.columns:\n",
    "            monthly_capacity_hist = cap_use.groupby(['department_id','month'], as_index=False).agg(capacity=('tickets_capacity','sum'))\n",
    "        elif 'avg_per_day' in cap_use.columns:\n",
    "            cap_use['wdays'] = cap_use['month'].apply(lambda d: working_days_in_month(d.year, d.month))\n",
    "            cap_use['capacity'] = cap_use['avg_per_day'] * cap_use['wdays']\n",
    "            monthly_capacity_hist = cap_use.groupby(['department_id','month'], as_index=False).agg(capacity=('capacity','sum'))\n",
    "        elif 'productive_hours' in cap_use.columns:\n",
    "            cap_use['capacity'] = cap_use['productive_hours'] * TARGET_TPH\n",
    "            monthly_capacity_hist = cap_use.groupby(['department_id','month'], as_index=False).agg(capacity=('capacity','sum'))\n",
    "        else:\n",
    "            monthly_capacity_hist = pd.DataFrame(columns=['department_id','month','capacity'])\n",
    "else:\n",
    "    monthly_capacity_hist = pd.DataFrame(columns=['department_id','month','capacity'])\n",
    "\n",
    "# Inventory\n",
    "if Path(INVENTORY_PATH).exists():\n",
    "    inv = pd.read_excel(INVENTORY_PATH, engine='openpyxl'); std_cols(inv)\n",
    "    i_date = pick_col(inv, ['Date','date']); i_dept = pick_col(inv, ['department_id','dept_id','Department_ID'])\n",
    "    if i_date and i_dept:\n",
    "        inv_use = inv[[i_date,i_dept]].copy(); inv_use.columns=['date','department_id']\n",
    "        inv_use['date']=pd.to_datetime(inv_use['date'], errors='coerce'); inv_use['month']=to_month_start(inv_use['date'])\n",
    "        inv_daily = inv_use.groupby(['department_id','date'], as_index=False).size().rename(columns={'size':'open_count'})\n",
    "        inv_daily['month']=to_month_start(inv_daily['date'])\n",
    "        monthly_inventory = inv_daily.groupby(['department_id','month'], as_index=False).agg(inventory_mean=('open_count','mean'))\n",
    "    else:\n",
    "        monthly_inventory = pd.DataFrame(columns=['department_id','month','inventory_mean'])\n",
    "else:\n",
    "    monthly_inventory = pd.DataFrame(columns=['department_id','month','inventory_mean'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a589f53",
   "metadata": {},
   "source": [
    "## 5) Recommended model mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee48e8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended models loaded for 0 departments (fallback Baseline for others).\n"
     ]
    }
   ],
   "source": [
    "\n",
    "recommended = {}  # department_id -> engine label\n",
    "# Option 1: read from previous remediation report (v17)\n",
    "try:\n",
    "    prev = pd.read_excel(os.path.join(OUTPUT_DIR, 'capacity_forecast_v17.xlsx'), sheet_name='Remediation_Report')\n",
    "    if {'department_id','Recommended_Model'}.issubset(prev.columns):\n",
    "        for _,r in prev.iterrows():\n",
    "            if pd.notna(r['department_id']) and pd.notna(r['Recommended_Model']):\n",
    "                recommended[int(r['department_id'])] = str(r['Recommended_Model'])\n",
    "except Exception:\n",
    "    pass\n",
    "# Option 2: read manual CSV\n",
    "try:\n",
    "    rm_csv = os.path.join(INPUT_DIR,'recommended_models.csv')\n",
    "    if Path(rm_csv).exists():\n",
    "        dfm = pd.read_csv(rm_csv)\n",
    "        if {'department_id','model'}.issubset(dfm.columns):\n",
    "            for _,r in dfm.iterrows():\n",
    "                recommended[int(r['department_id'])] = str(r['model'])\n",
    "except Exception:\n",
    "    pass\n",
    "print('Recommended models loaded for', len(recommended), 'departments (fallback Baseline for others).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae35e619",
   "metadata": {},
   "source": [
    "## 6) Daily forecast using per-department engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75cbc3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily forecast rows: 5840\n"
     ]
    }
   ],
   "source": [
    "\n",
    "incoming_daily = (incoming.groupby(['department_id','date'], as_index=False)\n",
    "                  .agg(tickets=('ticket_total','sum')))\n",
    "\n",
    "engine_funcs = {\n",
    "    'Baseline(STL)': forecast_daily_baseline,\n",
    "    'STL': forecast_daily_baseline,\n",
    "    'SARIMAX-7': forecast_daily_sarimax\n",
    "}\n",
    "\n",
    "daily_forecasts = []\n",
    "HORIZON_DAYS = 365\n",
    "for dpt_id, grp in incoming_daily.groupby('department_id'):\n",
    "    y = grp.set_index('date')['tickets'].sort_index().asfreq('D').fillna(0)\n",
    "    engine = recommended.get(int(dpt_id), 'Baseline(STL)')\n",
    "    func = engine_funcs.get(engine, forecast_daily_baseline)\n",
    "    try:\n",
    "        fc = func(y, horizon_days=HORIZON_DAYS)\n",
    "        if fc is None:\n",
    "            raise RuntimeError('Engine returned None')\n",
    "    except Exception:\n",
    "        fc = forecast_daily_baseline(y, horizon_days=HORIZON_DAYS)\n",
    "        engine = 'Baseline(STL)'\n",
    "    fc.insert(0, 'department_id', dpt_id)\n",
    "    fc['engine_used'] = engine\n",
    "    daily_forecasts.append(fc)\n",
    "\n",
    "fc_daily_built = pd.concat(daily_forecasts, ignore_index=True) if daily_forecasts else pd.DataFrame()\n",
    "fc_daily_built = fc_daily_built.merge(dept_map, on='department_id', how='left')\n",
    "fc_daily_built = fc_daily_built[fc_daily_built['vertical'].isin(VERTICALS_TARGET)]\n",
    "for tok in EXCLUDE_DEPARTMENT_NAME_TOKENS:\n",
    "    fc_daily_built = fc_daily_built[~fc_daily_built['department_name'].astype(str).str.upper().str.contains(tok.upper(), na=False)]\n",
    "\n",
    "fc_daily_built.rename(columns={'p50':'forecast_daily_dept','p05':'p05_daily_dept','p95':'p95_daily_dept'}, inplace=True)\n",
    "print('Daily forecast rows:', len(fc_daily_built))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89e83735",
   "metadata": {},
   "source": [
    "## 7) Monthly aggregation + Einstein deduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ef32556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly and Einstein prepared. 208 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pt3canro\\AppData\\Local\\Temp\\ipykernel_23920\\104079985.py:14: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda g: g.set_index('month')['einstein_rate'].tail(3).mean())\n"
     ]
    }
   ],
   "source": [
    "\n",
    "monthly_fc_raw = (fc_daily_built.assign(month=to_month_start(fc_daily_built['date']))\n",
    "                  .groupby(['vertical','department_id','department_name','month'], as_index=False)\n",
    "                  .agg(forecast_monthly_dept=('forecast_daily_dept','sum'),\n",
    "                       forecast_p05_dept=('p05_daily_dept','sum'),\n",
    "                       forecast_p95_dept=('p95_daily_dept','sum')))\n",
    "validate_quantiles(monthly_fc_raw)\n",
    "\n",
    "if not ein_month.empty:\n",
    "    hist_rates = monthly_actuals.merge(ein_month, on=['department_id','month'], how='left')\n",
    "    hist_rates['einstein_solved'] = hist_rates['einstein_solved'].fillna(0)\n",
    "    hist_rates['einstein_rate'] = (hist_rates['einstein_solved'] / hist_rates['actual_volume']).replace([np.inf,-np.inf], 0).fillna(0)\n",
    "    recent = (hist_rates.sort_values('month')\n",
    "              .groupby('department_id')\n",
    "              .apply(lambda g: g.set_index('month')['einstein_rate'].tail(3).mean())\n",
    "              .rename('einstein_rate_recent').reset_index())\n",
    "else:\n",
    "    recent = pd.DataFrame(columns=['department_id','einstein_rate_recent'])\n",
    "\n",
    "monthly_adj = monthly_fc_raw.merge(recent, on='department_id', how='left')\n",
    "monthly_adj['einstein_rate_recent'] = monthly_adj['einstein_rate_recent'].fillna(0).clip(0, 0.9)\n",
    "for c in ['forecast_monthly_dept','forecast_p05_dept','forecast_p95_dept']:\n",
    "    monthly_adj[c + '_post_einstein'] = monthly_adj[c] * (1 - monthly_adj['einstein_rate_recent'])\n",
    "\n",
    "print('Monthly and Einstein prepared.', len(monthly_adj), 'rows')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322b09eb",
   "metadata": {},
   "source": [
    "## 8) Bias-based calibration (from Model_Used_and_Error table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32a42da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration applied from bias table. Non-1 factors share: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_used_error_df = pd.DataFrame([\n",
    "    {'vertical':'Hospitality','department_id':7,'department_name':'CS_PMSH_L1','model_used':'STL','backtest_months':12,'mape_pct':29.35,'wape_pct':26.00,'bias_pct':-0.40},\n",
    "    {'vertical':'Hospitality','department_id':8,'department_name':'CS_PMSP_CLOUD_L1','model_used':'STL','backtest_months':12,'mape_pct':43.80,'wape_pct':39.12,'bias_pct':12.64},\n",
    "    {'vertical':'Hospitality','department_id':11,'department_name':'CS_PMSP_CLOUD_L2','model_used':'STL','backtest_months':12,'mape_pct':27.76,'wape_pct':22.27,'bias_pct':-4.06},\n",
    "    {'vertical':'Hospitality','department_id':23,'department_name':'CS_PMSP_FRANCE','model_used':'STL','backtest_months':12,'mape_pct':31.44,'wape_pct':25.79,'bias_pct':-1.79},\n",
    "    {'vertical':'Hospitality','department_id':5,'department_name':'CS_PMSP_INTEG','model_used':'STL','backtest_months':12,'mape_pct':20.88,'wape_pct':17.68,'bias_pct':-2.70},\n",
    "    {'vertical':'Hospitality','department_id':9,'department_name':'CS_PMSP_PREM_L1','model_used':'STL','backtest_months':12,'mape_pct':17.29,'wape_pct':14.44,'bias_pct':-3.07},\n",
    "    {'vertical':'Hospitality','department_id':10,'department_name':'CS_PMSP_PREM_L2','model_used':'STL','backtest_months':12,'mape_pct':28.77,'wape_pct':23.23,'bias_pct':-1.12},\n",
    "    {'vertical':'Partners','department_id':12,'department_name':'CS_PART_APAC','model_used':'STL','backtest_months':12,'mape_pct':20.88,'wape_pct':20.99,'bias_pct':-5.14},\n",
    "    {'vertical':'Partners','department_id':13,'department_name':'CS_PART_EMEA','model_used':'STL','backtest_months':12,'mape_pct':27.76,'wape_pct':25.91,'bias_pct':7.36},\n",
    "    {'vertical':'Partners','department_id':14,'department_name':'CS_PART_LATAM','model_used':'STL','backtest_months':12,'mape_pct':26.60,'wape_pct':21.38,'bias_pct':5.29},\n",
    "    {'vertical':'Partners','department_id':15,'department_name':'CS_PART_US','model_used':'STL','backtest_months':12,'mape_pct':40.03,'wape_pct':30.97,'bias_pct':-9.47},\n",
    "    {'vertical':'Payments','department_id':3,'department_name':'CA_PYAC','model_used':'STL','backtest_months':12,'mape_pct':18.63,'wape_pct':18.70,'bias_pct':1.28},\n",
    "    {'vertical':'Payments','department_id':1,'department_name':'CS_GT3C_EU','model_used':'STL','backtest_months':12,'mape_pct':24.80,'wape_pct':22.19,'bias_pct':0.58},\n",
    "    {'vertical':'Payments','department_id':18,'department_name':'Datatrans L2 Customer Support','model_used':'STL','backtest_months':12,'mape_pct':54.89,'wape_pct':38.55,'bias_pct':-7.28},\n",
    "    {'vertical':'Payments','department_id':2,'department_name':'L2 Customer Support','model_used':'STL','backtest_months':12,'mape_pct':28.56,'wape_pct':24.46,'bias_pct':-1.36},\n",
    "    {'vertical':'Payments','department_id':21,'department_name':'Specialist - L2 Customer Support','model_used':'STL','backtest_months':12,'mape_pct':42.25,'wape_pct':41.25,'bias_pct':17.26},\n",
    "])\n",
    "\n",
    "calib_from_bias = model_used_error_df[['department_id','bias_pct']].copy()\n",
    "calib_from_bias['department_id'] = pd.to_numeric(calib_from_bias['department_id'], errors='coerce')\n",
    "calib_from_bias['calib_factor'] = (1 - calib_from_bias['bias_pct']/100.0).clip(0.70, 1.30)\n",
    "\n",
    "monthly_adj = monthly_adj.drop(columns=['calib_factor'], errors='ignore')\n",
    "monthly_adj = monthly_adj.merge(calib_from_bias[['department_id','calib_factor']], on='department_id', how='left')\n",
    "monthly_adj['calib_factor'] = monthly_adj['calib_factor'].fillna(1.0)\n",
    "\n",
    "for c in ['forecast_monthly_dept_post_einstein','forecast_p05_dept_post_einstein','forecast_p95_dept_post_einstein']:\n",
    "    monthly_adj[c + '_cal'] = monthly_adj[c] * monthly_adj['calib_factor']\n",
    "\n",
    "print('Calibration applied from bias table. Non-1 factors share:', (monthly_adj['calib_factor']!=1.0).mean().round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b8c278e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "monthly_capacity_hist: (379, 3) | cap_proj: (480, 3) | monthly_capacity_all: (859, 3)\n"
     ]
    }
   ],
   "source": [
    "# =========================================\n",
    "# Build monthly_capacity_all from monthly_capacity_hist\n",
    "# - Historical capacity + projection for next HORIZON_MONTHS\n",
    "# =========================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1) Garantizar la existencia de monthly_capacity_hist\n",
    "if 'monthly_capacity_hist' not in globals() or monthly_capacity_hist is None:\n",
    "    monthly_capacity_hist = pd.DataFrame(columns=['department_id','month','capacity'])\n",
    "\n",
    "# 2) Normalizar tipos/fechas\n",
    "if not monthly_capacity_hist.empty:\n",
    "    monthly_capacity_hist = monthly_capacity_hist.copy()\n",
    "    monthly_capacity_hist['department_id'] = pd.to_numeric(monthly_capacity_hist['department_id'], errors='coerce')\n",
    "    monthly_capacity_hist['month'] = pd.to_datetime(monthly_capacity_hist['month'], errors='coerce').dt.to_period('M').dt.to_timestamp(how='start')\n",
    "    monthly_capacity_hist['capacity'] = pd.to_numeric(monthly_capacity_hist['capacity'], errors='coerce')\n",
    "\n",
    "# 3) Determinar último mes histórico\n",
    "last_hist_candidates = []\n",
    "\n",
    "if 'monthly_actuals' in globals() and isinstance(monthly_actuals, pd.DataFrame) and not monthly_actuals.empty:\n",
    "    last_hist_candidates.append(pd.to_datetime(monthly_actuals['month'], errors='coerce').max())\n",
    "\n",
    "if not monthly_capacity_hist.empty:\n",
    "    last_hist_candidates.append(monthly_capacity_hist['month'].max())\n",
    "\n",
    "if len(last_hist_candidates) > 0 and pd.notna(max(last_hist_candidates)):\n",
    "    last_hist_month = max(last_hist_candidates)\n",
    "else:\n",
    "    last_hist_month = pd.Timestamp.today().to_period('M').to_timestamp(how='start')\n",
    "\n",
    "# 4) Generar meses futuros (Month Start)\n",
    "if 'HORIZON_MONTHS' not in globals():\n",
    "    HORIZON_MONTHS = 12  # fallback\n",
    "\n",
    "first_future_month = last_hist_month + pd.offsets.MonthBegin(1)\n",
    "future_months = pd.date_range(first_future_month, periods=HORIZON_MONTHS, freq='MS')\n",
    "\n",
    "# 5) Proyección por departamento = media de las últimas 3 capacidades\n",
    "proj_rows = []\n",
    "if not monthly_capacity_hist.empty and len(future_months) > 0:\n",
    "    for dpt_id, g in monthly_capacity_hist.groupby('department_id'):\n",
    "        last3_mean = pd.to_numeric(g.sort_values('month').tail(3)['capacity'], errors='coerce').mean()\n",
    "        for m in future_months:\n",
    "            proj_rows.append({'department_id': dpt_id, 'month': m, 'capacity': last3_mean})\n",
    "\n",
    "cap_proj = pd.DataFrame(proj_rows, columns=['department_id','month','capacity'])\n",
    "\n",
    "# 6) Ensamblar ALL (histórico + proyección)\n",
    "monthly_capacity_all = pd.concat([monthly_capacity_hist, cap_proj], ignore_index=True)\n",
    "\n",
    "# 7) (Opcional) Comprobación rápida\n",
    "print(f\"monthly_capacity_hist: {monthly_capacity_hist.shape} | cap_proj: {cap_proj.shape} | monthly_capacity_all: {monthly_capacity_all.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a5047b",
   "metadata": {},
   "source": [
    "## 9) Export boards Board_[department]_2627 and Model_Used_and_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "db4f6a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export complete → C:\\Users\\pt3canro\\Desktop\\CAPACITY\\outputs\\capacity_forecast_v17_2.xlsx\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Build long_dept from calibrated forecast\n",
    "fc_board = monthly_adj.rename(columns={'forecast_monthly_dept_post_einstein_cal': 'forecast_adj_cal'})\n",
    "fc_board['forecast_adj_cal'] = monthly_adj['forecast_monthly_dept_post_einstein_cal']\n",
    "\n",
    "long_dept = (fc_board[['vertical','department_id','department_name','month','forecast_adj_cal']]\n",
    "             .merge(monthly_actuals[['vertical','department_id','department_name','month','actual_volume']],\n",
    "                    on=['vertical','department_id','department_name','month'], how='left')\n",
    "             .merge(monthly_capacity_all, on=['department_id','month'], how='left')\n",
    "             .merge(monthly_inventory,    on=['department_id','month'], how='left'))\n",
    "\n",
    "long_dept['productivity'] = long_dept['capacity']\n",
    "long_dept['forecast'] = long_dept['forecast_adj_cal']\n",
    "\n",
    "# Fixed window Jan-2026 → Feb-2027\n",
    "start_month = pd.Timestamp('2026-01-01')\n",
    "end_month   = pd.Timestamp('2027-02-01')\n",
    "month_range = pd.date_range(start_month, end_month, freq='MS')\n",
    "month_map = {1:'J',2:'F',3:'M',4:'A',5:'M',6:'J',7:'J',8:'A',9:'S',10:'O',11:'N',12:'D'}\n",
    "labels = [month_map[m.month] + '-' + str(m.year % 100).zfill(2) for m in month_range]\n",
    "\n",
    "def to_row_range(values: pd.Series, months: pd.Series, label_list: list) -> pd.Series:\n",
    "    lab = months.dt.month.map(month_map) + '-' + (months.dt.year % 100).astype(str).str.zfill(2)\n",
    "    s = pd.Series(values.to_numpy(), index=lab.to_numpy())\n",
    "    return s.reindex(label_list)\n",
    "\n",
    "def build_dept_matrix_range(long_dept_in: pd.DataFrame, department_name: str) -> pd.DataFrame:\n",
    "    base = long_dept_in.copy()\n",
    "    base = base[(base['department_name'] == department_name) & (base['month'] >= start_month) & (base['month'] <= end_month)]\n",
    "    agg_cols = {'forecast':'sum','actual_volume':'sum','capacity':'sum','productivity':'sum','inventory_mean':'mean'}\n",
    "    base = (base.groupby('month', as_index=False)\n",
    "                 .agg(**{k: pd.NamedAgg(column=k, aggfunc=v) for k,v in agg_cols.items()}))\n",
    "    base = base.set_index('month').reindex(month_range).reset_index().rename(columns={'index':'month'})\n",
    "    for c in ['forecast','actual_volume','capacity','productivity','inventory_mean']:\n",
    "        base[c] = pd.to_numeric(base[c], errors='coerce')\n",
    "\n",
    "    row_forecast = to_row_range(base['forecast'].round(0),      base['month'], labels)\n",
    "    row_actual   = to_row_range(base['actual_volume'].round(0), base['month'], labels)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        acc_vals = 100.0 - ((base['forecast'] - base['actual_volume']).abs() / base['actual_volume'] * 100.0)\n",
    "    row_acc = to_row_range(acc_vals.round(1), base['month'], labels)\n",
    "\n",
    "    row_capacity = to_row_range(base['capacity'],     base['month'], labels)\n",
    "    row_prod     = to_row_range(base['productivity'], base['month'], labels)\n",
    "    row_capacity = pd.to_numeric(row_capacity, errors='coerce')\n",
    "    row_prod     = pd.to_numeric(row_prod, errors='coerce')\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        diff_cap_prod = ((row_capacity - row_prod) / row_capacity * 100.0)\n",
    "    row_diff_cap_prod = diff_cap_prod.round(0).fillna(0).astype(int).astype(str) + '%'\n",
    "\n",
    "    row_exp_vs_cap = to_row_range((base['forecast'] - base['capacity']).round(0), base['month'], labels)\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        avp_vals = ((base['forecast'] - base['actual_volume']) / base['actual_volume'] * 100.0)\n",
    "    row_act_vs_prod = to_row_range(avp_vals.round(1), base['month'], labels)\n",
    "\n",
    "    row_inventory = to_row_range(base['inventory_mean'].round(2), base['month'], labels)\n",
    "    row_comments  = pd.Series(['']*len(labels), index=labels)\n",
    "\n",
    "    mat = pd.DataFrame({\n",
    "        'Comments': row_comments,\n",
    "        'Forecast': row_forecast,\n",
    "        'Actual Volume': row_actual,\n",
    "        'Forecast Accuracy': row_acc,\n",
    "        'Capacity': row_capacity,\n",
    "        'Productivity': row_prod,\n",
    "        'Difference Capacity vs Productivity': row_diff_cap_prod,\n",
    "        'Expected Forecast vs Capacity': row_exp_vs_cap,\n",
    "        'Actual Volume vs Productivity': row_act_vs_prod,\n",
    "        'Inventory': row_inventory\n",
    "    }).T\n",
    "    return mat\n",
    "\n",
    "# Write to Excel\n",
    "excel_path = Path(OUTPUT_XLSX)\n",
    "writer_mode = 'a' if excel_path.exists() else 'w'\n",
    "with pd.ExcelWriter(OUTPUT_XLSX, engine='openpyxl', mode=writer_mode, if_sheet_exists=('replace' if excel_path.exists() else None)) as writer:\n",
    "    if not excel_path.exists():\n",
    "        monthly_actuals.to_excel(writer, sheet_name='Monthly_Actuals', index=False)\n",
    "        monthly_fc_raw.to_excel(writer, sheet_name='Monthly_Forecast_RAW', index=False)\n",
    "        monthly_adj.to_excel(writer, sheet_name='Monthly_Forecast_CAL', index=False)\n",
    "        if 'monthly_capacity_hist' in globals() and isinstance(monthly_capacity_hist, pd.DataFrame) and not monthly_capacity_hist.empty:\n",
    "            monthly_capacity_hist.to_excel(writer, sheet_name='Monthly_Capacity_Hist', index=False)\n",
    "        if 'monthly_capacity_all' in globals() and isinstance(monthly_capacity_all, pd.DataFrame) and not monthly_capacity_all.empty:\n",
    "            monthly_capacity_all.to_excel(writer, sheet_name='Monthly_Capacity_All', index=False)\n",
    "        else:\n",
    "            pd.DataFrame(columns=['department_id','month','capacity']).to_excel(writer, sheet_name='Monthly_Capacity_All', index=False)\n",
    "        if 'monthly_inventory' in globals() and isinstance(monthly_inventory, pd.DataFrame) and not monthly_inventory.empty:\n",
    "            monthly_inventory.to_excel(writer, sheet_name='Monthly_Inventory', index=False)\n",
    "\n",
    "    for dname in sorted(long_dept['department_name'].dropna().unique().tolist()):\n",
    "        mat = build_dept_matrix_range(long_dept, dname)\n",
    "        base = str(dname).replace('/', '_').replace(':','_')  # avoid invalid chars\n",
    "        sh = f\"Board_{base}_2627\"\n",
    "        if len(sh) > 31: sh = sh[:31]\n",
    "        mat.to_excel(writer, sheet_name=sh)\n",
    "\n",
    "    model_used_error_df.to_excel(writer, sheet_name='Model_Used_and_Error', index=False)\n",
    "\n",
    "print('Export complete →', OUTPUT_XLSX)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
