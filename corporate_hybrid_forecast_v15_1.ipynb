{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42e849b4",
   "metadata": {},
   "source": [
    "# Planet | Capacity Forecast v15 (Stability‑First, Auditable)\n",
    "\n",
    "This notebook provides a **clean, minimal, and fully auditable** capacity forecasting pipeline.\n",
    "\n",
    "**Scope**\n",
    "- **Monthly forecast**: 12 months ahead (department-level, allocated from vertical forecasts)\n",
    "- **Daily plan**: 90 days ahead (department-level) using a historical **day-of-week (DOW) profile** (monthly forecast remains untouched)\n",
    "- **Languages**: Only `English, Spanish, Portuguese, French, German, Italian`. Any other language is mapped to **English**.\n",
    "\n",
    "**Modeling strategy (stability-first)**\n",
    "1. Aggregate incoming tickets to **monthly volumes per vertical**\n",
    "2. Forecast each vertical using **ETS (ExponentialSmoothing) only**\n",
    "3. Apply **vertical level recalibration** (last 3 months actual vs fitted)\n",
    "4. Allocate vertical forecast to departments using **EWMA shares** (renormalized per vertical-month)\n",
    "5. Compute **dept accuracy** via a clean rolling backtest (WAPE → Accuracy_staffing_%)\n",
    "\n",
    "Output Excel is saved under `outputs/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b84f898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE_DIR: C:\\Projects\\Capacity_forecast_2026\n",
      "INPUT_DIR: C:\\Projects\\Capacity_forecast_2026\\input_model\n",
      "OUTPUT_DIR: C:\\Projects\\Capacity_forecast_2026\\outputs\n",
      "Output file: C:\\Projects\\Capacity_forecast_2026\\outputs\\capacity_forecast_v15.xlsx\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# 0) Setup (interactive folder selector)\n",
    "# -----------------------------\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = r\"C:\\Projects\\Capacity_forecast_2026\"\n",
    "BASE_DIR = str(Path(BASE_DIR).expanduser().resolve())\n",
    "\n",
    "INPUT_DIR  = str(Path(BASE_DIR) / \"input_model\")\n",
    "OUTPUT_DIR = str(Path(BASE_DIR) / \"outputs\")\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "INCOMING_SOURCE_PATH = os.path.join(INPUT_DIR, \"Incoming_new.xlsx\")  # Sheet 'Main'\n",
    "INCOMING_SHEET = \"Main\"\n",
    "\n",
    "DEPT_MAP_PATH = os.path.join(INPUT_DIR, \"department.xlsx\")\n",
    "DEPT_MAP_SHEET = \"map\"\n",
    "\n",
    "PRODUCTIVITY_PATH = os.path.join(INPUT_DIR, \"productivity_agents.xlsx\")  # optional\n",
    "\n",
    "OUTPUT_XLSX = os.path.join(OUTPUT_DIR, \"capacity_forecast_v15.xlsx\")\n",
    "\n",
    "# Horizons\n",
    "H_MONTHS = 12\n",
    "DAILY_HORIZON_DAYS = 90\n",
    "\n",
    "# Prediction interval\n",
    "PI_ALPHA = 0.05  # 95% PI\n",
    "\n",
    "# Backtest settings\n",
    "BT_MIN_TRAIN_MONTHS = 12\n",
    "BT_EVAL_MONTHS = 9\n",
    "BT_HORIZON_MONTHS = 1\n",
    "BT_MAX_SPLITS = 9\n",
    "\n",
    "# Governance\n",
    "SUPPORTED_LANGUAGES = [\"English\",\"Spanish\",\"Portuguese\",\"French\",\"German\",\"Italian\"]\n",
    "DEFAULT_LANGUAGE = \"English\"\n",
    "\n",
    "CRITICAL_VERTICALS = [\"Payments\",\"Hospitality\",\"Partners\"]  # adjust if needed\n",
    "\n",
    "VERTICAL_LEVEL_ADJ = {\n",
    "    \"enabled\": True,\n",
    "    \"lookback_months\": 3,\n",
    "    \"clip_min\": 0.70,\n",
    "    \"clip_max\": 1.10,\n",
    "}\n",
    "\n",
    "DEPT_SHARE_EWMA_ALPHA = 0.50\n",
    "\n",
    "# DOW profile\n",
    "DOW_LOOKBACK_DAYS = 180\n",
    "DOW_MIN_OBS = 30\n",
    "WEEKEND_OPEN_THRESHOLD = 0.05  # if weekend share < 5%, treat dept as closed weekends for daily plan\n",
    "\n",
    "print(\"BASE_DIR:\", BASE_DIR)\n",
    "print(\"INPUT_DIR:\", INPUT_DIR)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"Output file:\", OUTPUT_XLSX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfa12ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1) Imports\n",
    "# -----------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional\n",
    "\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d050d7e9",
   "metadata": {},
   "source": [
    "## 2) Data loaders & standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f1a246",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_incoming(path: str, sheet: str = \"Main\") -> pd.DataFrame:\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "\n",
    "    if \"Date\" not in df.columns:\n",
    "        for c in [\"date\", \"created_date\", \"created_at\"]:\n",
    "            if c in df.columns:\n",
    "                df = df.rename(columns={c: \"Date\"})\n",
    "                break\n",
    "    if \"Date\" not in df.columns:\n",
    "        raise ValueError(\"Incoming_new.xlsx must contain a 'Date' column (or a recognizable alternative).\")\n",
    "\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"Date\"])\n",
    "\n",
    "    # Ticket weight: if absent, each row is 1 ticket\n",
    "    if \"ticket_total\" not in df.columns:\n",
    "        df[\"ticket_total\"] = 1.0\n",
    "    else:\n",
    "        df[\"ticket_total\"] = pd.to_numeric(df[\"ticket_total\"], errors=\"coerce\").fillna(1.0)\n",
    "\n",
    "    for col in [\"department_id\",\"department_name\",\"vertical\"]:\n",
    "        if col not in df.columns:\n",
    "            df[col] = np.nan\n",
    "\n",
    "    if \"language\" not in df.columns:\n",
    "        df[\"language\"] = DEFAULT_LANGUAGE\n",
    "    df[\"language\"] = df[\"language\"].fillna(DEFAULT_LANGUAGE).astype(str)\n",
    "    df.loc[~df[\"language\"].isin(SUPPORTED_LANGUAGES), \"language\"] = DEFAULT_LANGUAGE\n",
    "\n",
    "    df[\"department_id\"] = df[\"department_id\"].astype(str)\n",
    "    return df\n",
    "\n",
    "def load_dept_map(path: str, sheet: str = \"map\") -> pd.DataFrame:\n",
    "    m = pd.read_excel(path, sheet_name=sheet)\n",
    "    if \"department_id\" not in m.columns:\n",
    "        raise ValueError(\"department.xlsx must contain 'department_id'\")\n",
    "    m[\"department_id\"] = m[\"department_id\"].astype(str)\n",
    "    if \"vertical\" not in m.columns and \"vertical_name\" in m.columns:\n",
    "        m = m.rename(columns={\"vertical_name\":\"vertical\"})\n",
    "    return m\n",
    "\n",
    "def load_productivity(path: str) -> pd.DataFrame:\n",
    "    p = pd.read_excel(path)\n",
    "    if \"Date\" not in p.columns:\n",
    "        raise ValueError(\"productivity_agents.xlsx must contain 'Date'\")\n",
    "    p[\"Date\"] = pd.to_datetime(p[\"Date\"])\n",
    "    if \"prod_total_model\" in p.columns:\n",
    "        p[\"prod_total_model\"] = pd.to_numeric(p[\"prod_total_model\"], errors=\"coerce\").fillna(0.0)\n",
    "    else:\n",
    "        p[\"prod_total_model\"] = 0.0\n",
    "    for col in [\"department_id\",\"department_name\"]:\n",
    "        if col not in p.columns:\n",
    "            p[col] = np.nan\n",
    "    p[\"department_id\"] = p[\"department_id\"].astype(str)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8060f60",
   "metadata": {},
   "source": [
    "## 3) Monthly aggregates & shares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "088a375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monthly_vertical_series(incoming: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = incoming.copy()\n",
    "    d[\"month\"] = d[\"Date\"].dt.to_period(\"M\")\n",
    "    vm = d.groupby([\"vertical\",\"month\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    return vm.sort_values([\"vertical\",\"month\"])\n",
    "\n",
    "def monthly_dept_series(incoming: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = incoming.copy()\n",
    "    d[\"month\"] = d[\"Date\"].dt.to_period(\"M\")\n",
    "    dm = d.groupby([\"vertical\",\"department_id\",\"month\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    return dm.sort_values([\"vertical\",\"department_id\",\"month\"])\n",
    "\n",
    "def dept_share_ewma_within_vertical(incoming: pd.DataFrame, alpha: float = 0.5) -> pd.DataFrame:\n",
    "    dm = monthly_dept_series(incoming)\n",
    "    vm = monthly_vertical_series(incoming).rename(columns={\"ticket_total\":\"vertical_total\"})\n",
    "    x = dm.merge(vm, on=[\"vertical\",\"month\"], how=\"left\")\n",
    "    x[\"share\"] = np.where(x[\"vertical_total\"]>0, x[\"ticket_total\"]/x[\"vertical_total\"], 0.0)\n",
    "    x = x.sort_values([\"vertical\",\"department_id\",\"month\"])\n",
    "\n",
    "    x[\"share_ewma\"] = x.groupby([\"vertical\",\"department_id\"])[\"share\"].transform(\n",
    "        lambda s: s.ewm(alpha=alpha, adjust=False).mean()\n",
    "    )\n",
    "    denom = x.groupby([\"vertical\",\"month\"])[\"share_ewma\"].transform(\"sum\")\n",
    "    x[\"share_final\"] = np.where(denom>0, x[\"share_ewma\"]/denom, 0.0)\n",
    "\n",
    "    return x[[\"vertical\",\"department_id\",\"month\",\"share_final\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea367977",
   "metadata": {},
   "source": [
    "## 4) Vertical forecasting (ETS-only) + Level recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "397ddc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_ets_monthly(y_ts: pd.Series):\n",
    "    y_ts = pd.Series(y_ts).dropna().astype(float).sort_index()\n",
    "    if len(y_ts) < 6:\n",
    "        return None, float(y_ts.std()) if len(y_ts) else 0.0\n",
    "\n",
    "    try:\n",
    "        seasonal = \"add\" if len(y_ts) >= 24 else None\n",
    "        sp = 12 if seasonal else None\n",
    "        model = ExponentialSmoothing(\n",
    "            y_ts,\n",
    "            trend=\"add\",\n",
    "            seasonal=seasonal,\n",
    "            seasonal_periods=sp,\n",
    "            initialization_method=\"estimated\"\n",
    "        )\n",
    "        fit = model.fit(optimized=True)\n",
    "        resid = (y_ts - fit.fittedvalues).dropna()\n",
    "        sigma = float(resid.std()) if len(resid) else float(y_ts.std())\n",
    "        return fit, sigma\n",
    "    except Exception:\n",
    "        return None, float(y_ts.std()) if len(y_ts) else 0.0\n",
    "\n",
    "def forecast_vertical_final(incoming: pd.DataFrame, periods: int = 12, alpha: float = 0.05) -> pd.DataFrame:\n",
    "    vm = monthly_vertical_series(incoming)\n",
    "    rows = []\n",
    "\n",
    "    lookback = int(VERTICAL_LEVEL_ADJ[\"lookback_months\"])\n",
    "    clip_min = float(VERTICAL_LEVEL_ADJ[\"clip_min\"])\n",
    "    clip_max = float(VERTICAL_LEVEL_ADJ[\"clip_max\"])\n",
    "    enabled = bool(VERTICAL_LEVEL_ADJ[\"enabled\"])\n",
    "    z = 1.96  # ~95%\n",
    "\n",
    "    for v, g in vm.groupby(\"vertical\"):\n",
    "        y = g.set_index(\"month\")[\"ticket_total\"].sort_index()\n",
    "        y_ts = y.copy()\n",
    "        y_ts.index = y_ts.index.to_timestamp()\n",
    "\n",
    "        fit, sigma = fit_ets_monthly(y_ts)\n",
    "\n",
    "        last_m = y.index.max()\n",
    "        future_m = pd.period_range(last_m + 1, periods=periods, freq=\"M\")\n",
    "        future_idx = future_m.to_timestamp()\n",
    "\n",
    "        if fit is None:\n",
    "            last = float(y.iloc[-1]) if len(y) else 0.0\n",
    "            fc = pd.Series([last]*periods, index=future_idx)\n",
    "            fitted = pd.Series([last]*len(y_ts), index=y_ts.index)\n",
    "        else:\n",
    "            fc_vals = fit.forecast(periods)\n",
    "            fc = pd.Series(fc_vals.values, index=future_idx)\n",
    "            fitted = fit.fittedvalues\n",
    "\n",
    "        fc = fc.clip(lower=0.0)\n",
    "        p05 = (fc - z*sigma).clip(lower=0.0)\n",
    "        p95 = (fc + z*sigma).clip(lower=0.0)\n",
    "\n",
    "        factor = 1.0\n",
    "        if enabled and (v in CRITICAL_VERTICALS) and len(y_ts) >= lookback:\n",
    "            actual_last = float(y_ts.tail(lookback).mean())\n",
    "            fitted_last = float(fitted.tail(lookback).mean()) if len(fitted) else actual_last\n",
    "            if fitted_last > 0:\n",
    "                factor = float(np.clip(actual_last / fitted_last, clip_min, clip_max))\n",
    "\n",
    "        rows.append(pd.DataFrame({\n",
    "            \"vertical\": v,\n",
    "            \"month\": future_m,\n",
    "            \"forecast_monthly_vertical\": (fc*factor).values,\n",
    "            \"forecast_p05_vertical\": (p05*factor).values,\n",
    "            \"forecast_p95_vertical\": (p95*factor).values,\n",
    "            \"vertical_level_factor\": factor,\n",
    "            \"model_used\": \"ETS\"\n",
    "        }))\n",
    "\n",
    "    return pd.concat(rows, ignore_index=True) if rows else pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea35c175",
   "metadata": {},
   "source": [
    "## 5) Allocation to department (EWMA shares, renormalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef08e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def allocate_vertical_to_dept(fc_vertical: pd.DataFrame, shares_vd: pd.DataFrame) -> pd.DataFrame:\n",
    "    last_share = shares_vd.sort_values(\"month\").groupby([\"vertical\",\"department_id\"]).tail(1)\n",
    "    last_share = last_share[[\"vertical\",\"department_id\",\"share_final\"]].rename(columns={\"share_final\":\"share_cf\"})\n",
    "\n",
    "    fc = fc_vertical.copy()\n",
    "    fc = fc.merge(last_share, on=\"vertical\", how=\"left\")  # expands to depts per vertical\n",
    "    fc[\"share_cf\"] = fc[\"share_cf\"].fillna(0.0)\n",
    "\n",
    "    out = fc.assign(\n",
    "        forecast_monthly_dept = fc[\"forecast_monthly_vertical\"] * fc[\"share_cf\"],\n",
    "        forecast_p05_dept     = fc[\"forecast_p05_vertical\"]     * fc[\"share_cf\"],\n",
    "        forecast_p95_dept     = fc[\"forecast_p95_vertical\"]     * fc[\"share_cf\"],\n",
    "    )\n",
    "    return out[[\"vertical\",\"department_id\",\"month\",\n",
    "                \"forecast_monthly_dept\",\"forecast_p05_dept\",\"forecast_p95_dept\",\n",
    "                \"vertical_level_factor\",\"model_used\",\"share_cf\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b7b63b",
   "metadata": {},
   "source": [
    "## 6) Daily plan (90d) using DOW profile (monthly remains untouched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a19fb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dept_dow_profile(incoming: pd.DataFrame, lookback_days: int = 180, min_obs: int = 30) -> pd.DataFrame:\n",
    "    d = incoming.copy()\n",
    "    d = d[d[\"Date\"] >= (d[\"Date\"].max() - pd.Timedelta(days=lookback_days))]\n",
    "    daily = d.groupby([\"department_id\",\"Date\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    daily[\"dow\"] = pd.to_datetime(daily[\"Date\"]).dt.dayofweek\n",
    "\n",
    "    prof = daily.groupby([\"department_id\",\"dow\"], as_index=False)[\"ticket_total\"].sum()\n",
    "    tot = prof.groupby(\"department_id\")[\"ticket_total\"].transform(\"sum\")\n",
    "    prof[\"dow_share\"] = np.where(tot>0, prof[\"ticket_total\"]/tot, 0.0)\n",
    "\n",
    "    idx = pd.MultiIndex.from_product([prof[\"department_id\"].unique(), range(7)], names=[\"department_id\",\"dow\"])\n",
    "    prof = prof.set_index([\"department_id\",\"dow\"]).reindex(idx).reset_index()\n",
    "    prof[\"dow_share\"] = prof[\"dow_share\"].fillna(0.0)\n",
    "\n",
    "    obs = daily.groupby(\"department_id\")[\"Date\"].nunique().rename(\"n_days\").reset_index()\n",
    "    prof = prof.merge(obs, on=\"department_id\", how=\"left\")\n",
    "\n",
    "    def _fix(g):\n",
    "        if float(g[\"n_days\"].iloc[0] or 0) < min_obs:\n",
    "            g[\"dow_share\"] = 0.0\n",
    "            g.loc[g[\"dow\"].isin([0,1,2,3,4]), \"dow_share\"] = 0.2\n",
    "        else:\n",
    "            s = g[\"dow_share\"].sum()\n",
    "            if s > 0:\n",
    "                g[\"dow_share\"] = g[\"dow_share\"] / s\n",
    "        return g\n",
    "\n",
    "    prof = prof.groupby(\"department_id\", group_keys=False).apply(_fix)\n",
    "    return prof[[\"department_id\",\"dow\",\"dow_share\"]]\n",
    "\n",
    "def daily_plan_from_monthly(fc_dept_monthly: pd.DataFrame, dow_profile: pd.DataFrame,\n",
    "                            start_date: Optional[pd.Timestamp] = None, horizon_days: int = 90) -> pd.DataFrame:\n",
    "    if start_date is None:\n",
    "        start_date = pd.Timestamp.today().normalize()\n",
    "\n",
    "    end_date = start_date + pd.Timedelta(days=horizon_days-1)\n",
    "    days = pd.date_range(start_date, end_date, freq=\"D\")\n",
    "\n",
    "    day_df = pd.DataFrame({\"Date\": days})\n",
    "    day_df[\"month\"] = day_df[\"Date\"].dt.to_period(\"M\")\n",
    "    day_df[\"dow\"] = day_df[\"Date\"].dt.dayofweek\n",
    "\n",
    "    m = fc_dept_monthly.copy()\n",
    "    out = m.merge(day_df, on=\"month\", how=\"right\")\n",
    "    out[\"department_id\"] = out[\"department_id\"].astype(str)\n",
    "\n",
    "    out = out.merge(dow_profile, on=[\"department_id\",\"dow\"], how=\"left\")\n",
    "    out[\"dow_share\"] = out[\"dow_share\"].fillna(0.0)\n",
    "\n",
    "    wk = dow_profile.copy()\n",
    "    wk[\"is_weekend\"] = wk[\"dow\"].isin([5,6])\n",
    "    wk_sum = wk.groupby(\"department_id\").apply(lambda g: float(g.loc[g[\"is_weekend\"],\"dow_share\"].sum())).rename(\"weekend_share\").reset_index()\n",
    "    out = out.merge(wk_sum, on=\"department_id\", how=\"left\")\n",
    "    out[\"weekend_share\"] = out[\"weekend_share\"].fillna(0.0)\n",
    "\n",
    "    closed = out[\"weekend_share\"] < WEEKEND_OPEN_THRESHOLD\n",
    "    out.loc[closed & out[\"dow\"].isin([5,6]), \"dow_share\"] = 0.0\n",
    "\n",
    "    denom = out.groupby([\"department_id\",\"month\"])[\"dow_share\"].transform(\"sum\")\n",
    "    out[\"dow_share_adj\"] = np.where(denom>0, out[\"dow_share\"]/denom, 0.0)\n",
    "\n",
    "    out[\"forecast_daily_dept\"] = out[\"forecast_monthly_dept\"] * out[\"dow_share_adj\"]\n",
    "    out[\"p05_daily_dept\"]      = out[\"forecast_p05_dept\"]     * out[\"dow_share_adj\"]\n",
    "    out[\"p95_daily_dept\"]      = out[\"forecast_p95_dept\"]     * out[\"dow_share_adj\"]\n",
    "\n",
    "    return out[[\"Date\",\"vertical\",\"department_id\",\"month\",\"dow\",\n",
    "                \"forecast_daily_dept\",\"p05_daily_dept\",\"p95_daily_dept\",\n",
    "                \"forecast_monthly_dept\",\"forecast_p05_dept\",\"forecast_p95_dept\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10bc674",
   "metadata": {},
   "source": [
    "## 7) Backtest (clean, same pipeline, WAPE → Accuracy_staffing_%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd0027c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wape(y_true: pd.Series, y_pred: pd.Series) -> float:\n",
    "    y_true = pd.Series(y_true).astype(float)\n",
    "    y_pred = pd.Series(y_pred).astype(float)\n",
    "    denom = float(y_true.sum())\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    return float(np.abs(y_true - y_pred).sum() / denom)\n",
    "\n",
    "def backtest_dept_accuracy(\n",
    "    incoming: pd.DataFrame,\n",
    "    min_train_months: int = 12,\n",
    "    eval_months: int = 9,\n",
    "    horizon_months: int = 1,\n",
    "    max_splits: int = 9,\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    inc = incoming.copy()\n",
    "    inc[\"Date\"] = pd.to_datetime(inc[\"Date\"], errors=\"coerce\")\n",
    "    inc = inc.dropna(subset=[\"Date\"])\n",
    "    inc[\"month\"] = inc[\"Date\"].dt.to_period(\"M\")\n",
    "\n",
    "    all_months = sorted(inc[\"month\"].unique())\n",
    "    if len(all_months) < (min_train_months + horizon_months + 1):\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    eval_targets = all_months[-eval_months:]\n",
    "    splits = eval_targets[-max_splits:]\n",
    "    results = []\n",
    "\n",
    "    # cache dept->vertical\n",
    "    dept_vertical = None\n",
    "    if \"vertical\" in inc.columns:\n",
    "        dept_vertical = (\n",
    "            inc[[\"department_id\", \"vertical\"]]\n",
    "            .drop_duplicates(\"department_id\")\n",
    "            .copy()\n",
    "        )\n",
    "\n",
    "    for target_month in splits:\n",
    "\n",
    "        train_end = target_month - horizon_months\n",
    "        train = inc[inc[\"month\"] <= train_end].copy()\n",
    "        test = inc[inc[\"month\"] == target_month].copy()\n",
    "\n",
    "        if train[\"month\"].nunique() < min_train_months:\n",
    "            continue\n",
    "\n",
    "        shares_vd = dept_share_ewma_within_vertical(\n",
    "            train, alpha=DEPT_SHARE_EWMA_ALPHA\n",
    "        )\n",
    "\n",
    "        fc_vert = forecast_vertical_final(\n",
    "            train, periods=horizon_months, alpha=PI_ALPHA\n",
    "        ).copy()\n",
    "\n",
    "        if not pd.api.types.is_period_dtype(fc_vert[\"month\"]):\n",
    "            fc_vert[\"month\"] = pd.to_datetime(fc_vert[\"month\"]).dt.to_period(\"M\")\n",
    "\n",
    "        fc_vert = fc_vert[fc_vert[\"month\"] == target_month]\n",
    "        if fc_vert.empty:\n",
    "            continue\n",
    "\n",
    "        fc_dept = allocate_vertical_to_dept(fc_vert, shares_vd)\n",
    "\n",
    "        # Ensure vertical in fc_dept\n",
    "        if \"vertical\" not in fc_dept.columns:\n",
    "            if \"vertical\" in shares_vd.columns:\n",
    "                vd = shares_vd[[\"department_id\", \"vertical\"]].drop_duplicates()\n",
    "                fc_dept = fc_dept.merge(vd, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        if \"vertical\" not in fc_dept.columns and dept_vertical is not None:\n",
    "            fc_dept = fc_dept.merge(dept_vertical, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        if \"vertical\" not in fc_dept.columns:\n",
    "            fc_dept[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "        fc_dept[\"vertical\"] = (\n",
    "            fc_dept[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "        )\n",
    "\n",
    "        # Ensure vertical in test\n",
    "        if \"vertical\" not in test.columns and dept_vertical is not None:\n",
    "            test = test.merge(dept_vertical, on=\"department_id\", how=\"left\")\n",
    "\n",
    "        if \"vertical\" not in test.columns:\n",
    "            test[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "        test[\"vertical\"] = test[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "        actual = (\n",
    "            test.groupby([\"vertical\", \"department_id\"], as_index=False)[\n",
    "                \"ticket_total\"\n",
    "            ]\n",
    "            .sum()\n",
    "            .rename(columns={\"ticket_total\": \"actual\"})\n",
    "        )\n",
    "\n",
    "        pred = (\n",
    "            fc_dept.groupby([\"vertical\", \"department_id\"], as_index=False)[\n",
    "                \"forecast_monthly_dept\"\n",
    "            ]\n",
    "            .sum()\n",
    "            .rename(columns={\"forecast_monthly_dept\": \"forecast\"})\n",
    "        )\n",
    "\n",
    "        m = actual.merge(\n",
    "            pred, on=[\"vertical\", \"department_id\"], how=\"outer\"\n",
    "        ).fillna(0.0)\n",
    "\n",
    "        m[\"month\"] = target_month\n",
    "        results.append(m)\n",
    "\n",
    "    if not results:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    bt = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    def _metrics(g: pd.DataFrame) -> pd.Series:\n",
    "        y = g[\"actual\"].values.astype(float)\n",
    "        yhat = g[\"forecast\"].values.astype(float)\n",
    "\n",
    "        mae = float(np.mean(np.abs(y - yhat)))\n",
    "        bias = (\n",
    "            float((yhat.sum() - y.sum()) / y.sum() * 100)\n",
    "            if y.sum() > 0\n",
    "            else np.nan\n",
    "        )\n",
    "        wape = (\n",
    "            compute_wape(y, yhat) * 100\n",
    "            if y.sum() > 0\n",
    "            else np.nan\n",
    "        )\n",
    "        acc = (\n",
    "            max(0.0, 100.0 - wape)\n",
    "            if np.isfinite(wape)\n",
    "            else np.nan\n",
    "        )\n",
    "\n",
    "        return pd.Series(\n",
    "            {\n",
    "                \"MAE\": mae,\n",
    "                \"Bias_%\": bias,\n",
    "                \"WAPE_%\": wape,\n",
    "                \"Accuracy_staffing_%\": acc,\n",
    "            }\n",
    "        )\n",
    "\n",
    "    out = (\n",
    "        bt.groupby([\"vertical\", \"department_id\"])\n",
    "        .apply(_metrics)\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    out[\"Eval_Months\"] = (\n",
    "        bt.groupby([\"vertical\", \"department_id\"])[\"month\"]\n",
    "        .nunique()\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a68e7",
   "metadata": {},
   "source": [
    "## 8) Run end-to-end pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966ada6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incoming rows: 477947\n",
      "Verticals: ['Finance', 'Hospitality', 'Partners', 'Payments', 'Rebag']\n",
      "Departments: 24\n",
      "Share sum (min/max): 0.9999999999999999 1.0000000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:903: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\holtwinters\\model.py:903: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Vertical factors (sanity):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:473: ValueWarning: A date index has been provided, but it has no associated frequency information and so will be ignored when e.g. forecasting.\n",
      "  self._init_dates(dates, freq)\n",
      "c:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\statsmodels\\tsa\\base\\tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n",
      "  return get_prediction_index(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertical</th>\n",
       "      <th>vertical_level_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Payments</td>\n",
       "      <td>0.823786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>0.846652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Partners</td>\n",
       "      <td>0.865251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finance</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rebag</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      vertical  vertical_level_factor\n",
       "3     Payments               0.823786\n",
       "1  Hospitality               0.846652\n",
       "2     Partners               0.865251\n",
       "0      Finance               1.000000\n",
       "4        Rebag               1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy table (top 15 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vertical</th>\n",
       "      <th>department_id</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Bias_%</th>\n",
       "      <th>WAPE_%</th>\n",
       "      <th>Accuracy_staffing_%</th>\n",
       "      <th>Eval_Months</th>\n",
       "      <th>department_name</th>\n",
       "      <th>department_group</th>\n",
       "      <th>team_hierarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Finance</td>\n",
       "      <td>58</td>\n",
       "      <td>3206.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Billing L1</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Billing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Finance</td>\n",
       "      <td>60</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>Billing L2</td>\n",
       "      <td>Finance</td>\n",
       "      <td>Billing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>10</td>\n",
       "      <td>145.707579</td>\n",
       "      <td>20.654845</td>\n",
       "      <td>25.657762</td>\n",
       "      <td>74.342238</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_PREM_L2</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>11</td>\n",
       "      <td>124.318424</td>\n",
       "      <td>27.630308</td>\n",
       "      <td>37.520651</td>\n",
       "      <td>62.479349</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_CLOUD_L2</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>23</td>\n",
       "      <td>149.223072</td>\n",
       "      <td>11.448398</td>\n",
       "      <td>23.791101</td>\n",
       "      <td>76.208899</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_FRANCE</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>4</td>\n",
       "      <td>89.683024</td>\n",
       "      <td>4248.143222</td>\n",
       "      <td>4248.143222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_DIST</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>44</td>\n",
       "      <td>1.329121</td>\n",
       "      <td>1196.208661</td>\n",
       "      <td>1196.208661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_PROJ</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>5</td>\n",
       "      <td>258.926385</td>\n",
       "      <td>18.712232</td>\n",
       "      <td>20.468489</td>\n",
       "      <td>79.531511</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_INTEG</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>6</td>\n",
       "      <td>125.192513</td>\n",
       "      <td>7.228863</td>\n",
       "      <td>127.747462</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_KEY</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>7</td>\n",
       "      <td>250.811964</td>\n",
       "      <td>6.408972</td>\n",
       "      <td>17.599467</td>\n",
       "      <td>82.400533</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSH_L1</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Hoist PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>8</td>\n",
       "      <td>137.113631</td>\n",
       "      <td>14.451268</td>\n",
       "      <td>20.349978</td>\n",
       "      <td>79.650022</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_CLOUD_L1</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hospitality</td>\n",
       "      <td>9</td>\n",
       "      <td>168.172326</td>\n",
       "      <td>9.495866</td>\n",
       "      <td>12.852844</td>\n",
       "      <td>87.147156</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PMSP_PREM_L1</td>\n",
       "      <td>Planet Hospitality - PMS</td>\n",
       "      <td>Protel PMS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Partners</td>\n",
       "      <td>12</td>\n",
       "      <td>127.077558</td>\n",
       "      <td>3.565699</td>\n",
       "      <td>30.835751</td>\n",
       "      <td>69.164249</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_APAC</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Partners</td>\n",
       "      <td>13</td>\n",
       "      <td>183.239499</td>\n",
       "      <td>16.275503</td>\n",
       "      <td>50.217889</td>\n",
       "      <td>49.782111</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_EMEA</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Partners</td>\n",
       "      <td>14</td>\n",
       "      <td>72.970930</td>\n",
       "      <td>-0.222675</td>\n",
       "      <td>34.821759</td>\n",
       "      <td>65.178241</td>\n",
       "      <td>9</td>\n",
       "      <td>CS_PART_LATAM</td>\n",
       "      <td>Planet Partners Support</td>\n",
       "      <td>Partners</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       vertical department_id          MAE       Bias_%       WAPE_%  \\\n",
       "0       Finance            58  3206.000000     0.000000   200.000000   \n",
       "1       Finance            60    39.000000     0.000000   200.000000   \n",
       "2   Hospitality            10   145.707579    20.654845    25.657762   \n",
       "3   Hospitality            11   124.318424    27.630308    37.520651   \n",
       "4   Hospitality            23   149.223072    11.448398    23.791101   \n",
       "5   Hospitality             4    89.683024  4248.143222  4248.143222   \n",
       "6   Hospitality            44     1.329121  1196.208661  1196.208661   \n",
       "7   Hospitality             5   258.926385    18.712232    20.468489   \n",
       "8   Hospitality             6   125.192513     7.228863   127.747462   \n",
       "9   Hospitality             7   250.811964     6.408972    17.599467   \n",
       "10  Hospitality             8   137.113631    14.451268    20.349978   \n",
       "11  Hospitality             9   168.172326     9.495866    12.852844   \n",
       "12     Partners            12   127.077558     3.565699    30.835751   \n",
       "13     Partners            13   183.239499    16.275503    50.217889   \n",
       "14     Partners            14    72.970930    -0.222675    34.821759   \n",
       "\n",
       "    Accuracy_staffing_%  Eval_Months   department_name  \\\n",
       "0              0.000000            2        Billing L1   \n",
       "1              0.000000            2        Billing L2   \n",
       "2             74.342238            9   CS_PMSP_PREM_L2   \n",
       "3             62.479349            9  CS_PMSP_CLOUD_L2   \n",
       "4             76.208899            9    CS_PMSP_FRANCE   \n",
       "5              0.000000            9      CS_PMSP_DIST   \n",
       "6              0.000000            9      CS_PMSP_PROJ   \n",
       "7             79.531511            9     CS_PMSP_INTEG   \n",
       "8              0.000000            9       CS_PMSP_KEY   \n",
       "9             82.400533            9        CS_PMSH_L1   \n",
       "10            79.650022            9  CS_PMSP_CLOUD_L1   \n",
       "11            87.147156            9   CS_PMSP_PREM_L1   \n",
       "12            69.164249            9      CS_PART_APAC   \n",
       "13            49.782111            9      CS_PART_EMEA   \n",
       "14            65.178241            9     CS_PART_LATAM   \n",
       "\n",
       "            department_group team_hierarchy  \n",
       "0                    Finance        Billing  \n",
       "1                    Finance        Billing  \n",
       "2   Planet Hospitality - PMS     Protel PMS  \n",
       "3   Planet Hospitality - PMS     Protel PMS  \n",
       "4   Planet Hospitality - PMS     Protel PMS  \n",
       "5   Planet Hospitality - PMS     Protel PMS  \n",
       "6    Planet Partners Support     Protel PMS  \n",
       "7   Planet Hospitality - PMS     Protel PMS  \n",
       "8   Planet Hospitality - PMS     Protel PMS  \n",
       "9   Planet Hospitality - PMS      Hoist PMS  \n",
       "10  Planet Hospitality - PMS     Protel PMS  \n",
       "11  Planet Hospitality - PMS     Protel PMS  \n",
       "12   Planet Partners Support       Partners  \n",
       "13   Planet Partners Support       Partners  \n",
       "14   Planet Partners Support       Partners  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "incoming = load_incoming(INCOMING_SOURCE_PATH, INCOMING_SHEET)\n",
    "mapping = load_dept_map(DEPT_MAP_PATH, DEPT_MAP_SHEET)\n",
    "\n",
    "incoming = incoming.merge(mapping, on=\"department_id\", how=\"left\", suffixes=(\"\",\"_map\"))\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# SAFE COALESCE: vertical + department_name (v15.1)\n",
    "# Guarantees columns exist and prevents KeyError: 'vertical'\n",
    "# -----------------------------\n",
    "if \"vertical\" not in incoming.columns:\n",
    "    incoming[\"vertical\"] = pd.NA\n",
    "if \"department_name\" not in incoming.columns:\n",
    "    incoming[\"department_name\"] = pd.NA\n",
    "\n",
    "if \"vertical_map\" in incoming.columns:\n",
    "    incoming[\"vertical\"] = incoming[\"vertical_map\"].combine_first(incoming[\"vertical\"])\n",
    "if \"department_name_map\" in incoming.columns:\n",
    "    incoming[\"department_name\"] = incoming[\"department_name_map\"].combine_first(incoming[\"department_name\"])\n",
    "\n",
    "incoming[\"vertical\"] = incoming[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "incoming[\"department_name\"] = incoming[\"department_name\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "if \"vertical_map\" in incoming.columns:\n",
    "    incoming[\"vertical\"] = incoming[\"vertical_map\"].combine_first(incoming[\"vertical\"])\n",
    "if \"department_name_map\" in incoming.columns:\n",
    "    incoming[\"department_name\"] = incoming[\"department_name_map\"].combine_first(incoming[\"department_name\"])\n",
    "\n",
    "incoming[\"vertical\"] = incoming[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "incoming[\"department_name\"] = incoming[\"department_name\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "print(\"Incoming rows:\", len(incoming))\n",
    "print(\"Verticals:\", sorted(incoming[\"vertical\"].unique().tolist()))\n",
    "print(\"Departments:\", incoming[\"department_id\"].nunique())\n",
    "\n",
    "# Shares\n",
    "shares_vd = dept_share_ewma_within_vertical(incoming, alpha=DEPT_SHARE_EWMA_ALPHA)\n",
    "san = shares_vd.groupby([\"vertical\",\"month\"])[\"share_final\"].sum().reset_index(name=\"share_sum\")\n",
    "print(\"Share sum (min/max):\", float(san[\"share_sum\"].min()), float(san[\"share_sum\"].max()))\n",
    "\n",
    "# Forecasts\n",
    "fc_vertical = forecast_vertical_final(incoming, periods=H_MONTHS, alpha=PI_ALPHA)\n",
    "fc_dept = allocate_vertical_to_dept(fc_vertical, shares_vd).merge(mapping, on=\"department_id\", how=\"left\")\n",
    "\n",
    "# -----------------------------\n",
    "# v15.1 GUARDAESPALDAS: fc_dept SIEMPRE con 'vertical'\n",
    "# -----------------------------\n",
    "if \"vertical\" not in fc_dept.columns:\n",
    "    # 1) Preferencia: traértelo desde shares_vd (vertical-dept real del share)\n",
    "    if \"vertical\" in shares_vd.columns:\n",
    "        vd = shares_vd[[\"department_id\", \"vertical\"]].drop_duplicates(\"department_id\")\n",
    "        fc_dept = fc_dept.merge(vd, on=\"department_id\", how=\"left\")\n",
    "\n",
    "# 2) Si aún no está, fallback a mapping\n",
    "if \"vertical\" not in fc_dept.columns:\n",
    "    if \"vertical\" in mapping.columns:\n",
    "        fc_dept = fc_dept.merge(\n",
    "            mapping[[\"department_id\", \"vertical\"]],\n",
    "            on=\"department_id\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_map\")\n",
    "        )\n",
    "\n",
    "# 3) Normaliza nombre si quedó como vertical_map\n",
    "if \"vertical\" not in fc_dept.columns and \"vertical_map\" in fc_dept.columns:\n",
    "    fc_dept[\"vertical\"] = fc_dept[\"vertical_map\"]\n",
    "\n",
    "# 4) Último recurso\n",
    "if \"vertical\" not in fc_dept.columns:\n",
    "    fc_dept[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "fc_dept[\"vertical\"] = fc_dept[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Daily plan\n",
    "dow_profile = compute_dept_dow_profile(incoming, lookback_days=DOW_LOOKBACK_DAYS, min_obs=DOW_MIN_OBS)\n",
    "needed = [\"vertical\",\"department_id\",\"month\",\"forecast_monthly_dept\",\"forecast_p05_dept\",\"forecast_p95_dept\"]\n",
    "missing = [c for c in needed if c not in fc_dept.columns]\n",
    "if missing:\n",
    "    raise ValueError(f\"fc_dept missing columns for daily plan: {missing}. Columns={list(fc_dept.columns)}\")\n",
    "\n",
    "daily_plan = daily_plan_from_monthly(\n",
    "    fc_dept_monthly=fc_dept[needed],\n",
    "    dow_profile=dow_profile,\n",
    "    start_date=pd.Timestamp.today().normalize(),\n",
    "    horizon_days=DAILY_HORIZON_DAYS\n",
    ").merge(mapping, on=\"department_id\", how=\"left\")\n",
    "\n",
    "\n",
    "# --- v15.1: asegurar vertical en daily_plan ---\n",
    "if \"vertical\" not in daily_plan.columns:\n",
    "    if \"vertical\" in fc_dept.columns:\n",
    "        daily_plan = daily_plan.merge(\n",
    "            fc_dept[[\"department_id\", \"vertical\"]].drop_duplicates(\"department_id\"),\n",
    "            on=\"department_id\",\n",
    "            how=\"left\",\n",
    "        )\n",
    "    elif \"vertical\" in mapping.columns:\n",
    "        daily_plan = daily_plan.merge(\n",
    "            mapping[[\"department_id\", \"vertical\"]],\n",
    "            on=\"department_id\",\n",
    "            how=\"left\",\n",
    "            suffixes=(\"\", \"_map\"),\n",
    "        )\n",
    "        if \"vertical_map\" in daily_plan.columns:\n",
    "            daily_plan[\"vertical\"] = daily_plan.get(\"vertical\").fillna(daily_plan[\"vertical_map\"])\n",
    "\n",
    "if \"vertical\" not in daily_plan.columns:\n",
    "    daily_plan[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "daily_plan[\"vertical\"] = daily_plan[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Backtest\n",
    "acc_dept = backtest_dept_accuracy(\n",
    "    incoming,\n",
    "    min_train_months=BT_MIN_TRAIN_MONTHS,\n",
    "    eval_months=BT_EVAL_MONTHS,\n",
    "    horizon_months=BT_HORIZON_MONTHS,\n",
    "    max_splits=BT_MAX_SPLITS\n",
    ")\n",
    "\n",
    "# Merge mapping (keep dept metadata) without breaking vertical\n",
    "acc_dept = acc_dept.merge(mapping, on=\"department_id\", how=\"left\", suffixes=(\"\", \"_map\"))\n",
    "\n",
    "# Consolidate vertical if merge created duplicates\n",
    "if \"vertical\" not in acc_dept.columns:\n",
    "    if \"vertical_x\" in acc_dept.columns or \"vertical_y\" in acc_dept.columns:\n",
    "        vx = acc_dept[\"vertical_x\"] if \"vertical_x\" in acc_dept.columns else pd.Series([pd.NA]*len(acc_dept))\n",
    "        vy = acc_dept[\"vertical_y\"] if \"vertical_y\" in acc_dept.columns else pd.Series([pd.NA]*len(acc_dept))\n",
    "        acc_dept[\"vertical\"] = vx.fillna(vy)\n",
    "    elif \"vertical_map\" in acc_dept.columns:\n",
    "        acc_dept[\"vertical\"] = acc_dept[\"vertical_map\"]\n",
    "\n",
    "if \"vertical\" not in acc_dept.columns:\n",
    "    acc_dept[\"vertical\"] = \"Unknown\"\n",
    "\n",
    "acc_dept[\"vertical\"] = acc_dept[\"vertical\"].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "# Clean duplicates if present\n",
    "drop_cols = [c for c in [\"vertical_x\", \"vertical_y\", \"vertical_map\"] if c in acc_dept.columns]\n",
    "if drop_cols:\n",
    "    acc_dept = acc_dept.drop(columns=drop_cols)\n",
    "\n",
    "acc_dept = acc_dept.sort_values([\"vertical\", \"department_id\"]) if not acc_dept.empty else acc_dept\n",
    "\n",
    "print(\"\\nVertical factors (sanity):\")\n",
    "display(fc_vertical.groupby(\"vertical\", as_index=False)[\"vertical_level_factor\"].mean().sort_values(\"vertical_level_factor\"))\n",
    "\n",
    "print(\"\\nAccuracy table (top 15 rows):\")\n",
    "display(acc_dept.head(15))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34b0939",
   "metadata": {},
   "source": [
    "## 9) Export to Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e20a56bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'vertical'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_16312\\1826922252.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m pd.ExcelWriter(OUTPUT_XLSX, engine=\u001b[33m\"openpyxl\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[32m      2\u001b[39m     fc_vertical.sort_values([\u001b[33m\"vertical\"\u001b[39m,\u001b[33m\"month\"\u001b[39m]).to_excel(w, \u001b[33m\"forecast_vertical_monthly\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m     fc_dept.sort_values([\u001b[33m\"vertical\"\u001b[39m,\u001b[33m\"department_id\"\u001b[39m,\u001b[33m\"month\"\u001b[39m]).to_excel(w, \u001b[33m\"forecast_dept_monthly\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     daily_plan.sort_values([\u001b[33m\"vertical\"\u001b[39m,\u001b[33m\"department_id\"\u001b[39m,\u001b[33m\"Date\"\u001b[39m]).to_excel(w, \u001b[33m\"daily_plan_90d\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      5\u001b[39m     shares_vd.sort_values([\u001b[33m\"vertical\"\u001b[39m,\u001b[33m\"department_id\"\u001b[39m,\u001b[33m\"month\"\u001b[39m]).to_excel(w, \u001b[33m\"dept_share_ewma\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m     dow_profile.sort_values([\u001b[33m\"department_id\"\u001b[39m,\u001b[33m\"dow\"\u001b[39m]).to_excel(w, \u001b[33m\"dept_dow_profile\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m     acc_dept.sort_values([\u001b[33m\"vertical\"\u001b[39m,\u001b[33m\"department_id\"\u001b[39m]).to_excel(w, \u001b[33m\"accuracy_dept_monthly\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[32mc:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7190\u001b[39m                 \u001b[33mf\"Length of ascending ({len(ascending)})\"\u001b[39m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m   7191\u001b[39m                 \u001b[33mf\" != length of by ({len(by)})\"\u001b[39m\n\u001b[32m   7192\u001b[39m             )\n\u001b[32m   7193\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m len(by) > \u001b[32m1\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m7194\u001b[39m             keys = [self._get_label_or_level_values(x, axis=axis) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;28;01min\u001b[39;00m by]\n\u001b[32m   7195\u001b[39m \n\u001b[32m   7196\u001b[39m             \u001b[38;5;66;03m# need to rewrap columns in Series to apply key function\u001b[39;00m\n\u001b[32m   7197\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32mc:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m7194\u001b[39m         ...     key=\u001b[38;5;28;01mlambda\u001b[39;00m x: np.argsort(index_natsorted(df[\u001b[33m\"time\"\u001b[39m]))\n",
      "\u001b[32mc:\\Users\\anto-\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1910\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1911\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1912\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1913\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1915\u001b[39m \n\u001b[32m   1916\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1917\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'vertical'"
     ]
    }
   ],
   "source": [
    "with pd.ExcelWriter(OUTPUT_XLSX, engine=\"openpyxl\") as w:\n",
    "    fc_vertical.sort_values([\"vertical\",\"month\"]).to_excel(w, \"forecast_vertical_monthly\", index=False)\n",
    "    fc_dept.sort_values([\"vertical\",\"department_id\",\"month\"]).to_excel(w, \"forecast_dept_monthly\", index=False)\n",
    "    daily_plan.sort_values([\"vertical\",\"department_id\",\"Date\"]).to_excel(w, \"daily_plan_90d\", index=False)\n",
    "    shares_vd.sort_values([\"vertical\",\"department_id\",\"month\"]).to_excel(w, \"dept_share_ewma\", index=False)\n",
    "    dow_profile.sort_values([\"department_id\",\"dow\"]).to_excel(w, \"dept_dow_profile\", index=False)\n",
    "    acc_dept.sort_values([\"vertical\",\"department_id\"]).to_excel(w, \"accuracy_dept_monthly\", index=False)\n",
    "\n",
    "print(\"Saved:\", OUTPUT_XLSX)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
