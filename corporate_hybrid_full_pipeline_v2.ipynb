{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e709ee08",
   "metadata": {},
   "source": [
    "# Corporate Hybrid Forecast Notebook (Prophet + ARIMA) â€“ v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f323b68",
   "metadata": {},
   "source": [
    "## 01 - Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c4f3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hybrid 3-Way (Prophet vs ARIMA vs TBATS/ETS) with 12-month horizon,\n",
    "capacity report, and daily capacity plan with language split.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Forecasting libs\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "try:\n",
    "    from prophet import Prophet\n",
    "except Exception:\n",
    "    Prophet = None\n",
    "\n",
    "try:\n",
    "    from tbats import TBATS\n",
    "except Exception:\n",
    "    TBATS = None\n",
    "\n",
    "# Pandas engines\n",
    "PD_READ_XLSX_ENGINE = 'openpyxl'\n",
    "PD_WRITE_XLSX_ENGINE = 'openpyxl'\n",
    "\n",
    "# === Project paths (adapt to your local if needed) ===\n",
    "INPUT_FOLDER  = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\\input_model\"\n",
    "OUTPUT_FOLDER = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\\outputs\"\n",
    "\n",
    "# Source files (as in your original pipeline)\n",
    "INCOMING_PATH   = os.path.join(INPUT_FOLDER, \"Incoming_new.xlsx\")\n",
    "CALL_PATH       = os.path.join(INPUT_FOLDER, \"call_performance.xlsx\")\n",
    "AGENTS_PATH     = os.path.join(INPUT_FOLDER, \"agent_language_n_target.xlsx\")\n",
    "PROD_PATH       = os.path.join(INPUT_FOLDER, \"productivity_agents.xlsx\")\n",
    "EINSTEIN_PATH   = os.path.join(INPUT_FOLDER, \"einstein.xlsx\")\n",
    "INVENTORY_PATH  = os.path.join(INPUT_FOLDER, \"inventory_month.xlsx\")\n",
    "DEPT_PATH  = os.path.join(INPUT_FOLDER, \"department.xlsx\")   # official mapping source\n",
    "DEPT_SHEET = None\n",
    "\n",
    "# Output files\n",
    "OUT_XLSX = \"capacity_forecast_hybrid.xlsx\"\n",
    "OUT_MAPE = \"mape_by_department.xlsx\"\n",
    "\n",
    "# Forecast horizon\n",
    "HORIZON_MONTHS = 6\n",
    "\n",
    "# Language shares (fixed)\n",
    "LANG_SHARE = {\n",
    "    'English': 64.35,\n",
    "    'French' : 7.41,\n",
    "    'German' : 8.60,\n",
    "    'Italian': 6.67,\n",
    "    'Portuguese': 1.62,\n",
    "    'Spanish': 11.35,\n",
    "}\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Configuration\n",
    "# ---------------------------\n",
    "\n",
    "H_MONTHS = 12                        # 12-month horizon for monthly report\n",
    "DAILY_HORIZON_DAYS = 90              # Days predicted 90 days ahead\n",
    "USE_DAILY_MODELLING = True           # If False, disaggregate monthly -> daily\n",
    "WEEKLY_START_THU = True              # Your organization uses Thu-Wed weeks\n",
    "\n",
    "# Language shares (fixed)\n",
    "LANGUAGE_SHARES = {\n",
    "    'English': 0.6435,\n",
    "    'French': 0.0741,\n",
    "    'German': 0.0860,\n",
    "    'Italian': 0.0667,\n",
    "    'Portuguese': 0.0162,\n",
    "    'Spanish': 0.1135\n",
    "}\n",
    "\n",
    "# Inputs\n",
    "# Incoming daily volumes (ensure at least these columns): Date, department_id, ticket_total\n",
    "INCOMING_SOURCE_PATH = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\\input_model\\Incoming_daily.csv\"  # Example CSV\n",
    "# Optional mapping file to fix Vertical & department names (sheet or CSV)\n",
    "DEPT_MAP_PATH = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\\input_model\\departments_map.xlsx\"       # Example\n",
    "DEPT_MAP_SHEET = \"map\"  # columns: department_id, department_name, vertical\n",
    "\n",
    "# Productivity file (as you indicated)\n",
    "PRODUCTIVITY_PATH = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\\input_model\\productivity_agents.xlsx\"  # columns: Date, agent_id, agent_name, department_id, department_name, prod_total_model\n",
    "\n",
    "# Output\n",
    "OUTPUT_XLSX = r\"C:\\Users\\pt3canro\\Desktop\\CAPACITY\\output\\capacity_forecast_hybrid.xlsx\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3c5b8a",
   "metadata": {},
   "source": [
    "## 02. Data loading and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "584ba1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_incoming(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load daily incoming volumes. Expected columns: Date, department_id, ticket_total. department_name optional.\"\"\"\n",
    "    # Try CSV then Excel\n",
    "    if path.lower().endswith(\".csv\"):\n",
    "        df = pd.read_csv(path)\n",
    "    else:\n",
    "        df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "    # Basic normalization\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['department_id'] = df['department_id'].astype(str).str.strip()\n",
    "    if 'department_name' in df.columns:\n",
    "        df['department_name'] = df['department_name'].astype(str).str.strip()\n",
    "    else:\n",
    "        df['department_name'] = None\n",
    "    df['ticket_total'] = pd.to_numeric(df['ticket_total'], errors='coerce').fillna(0).astype(float)\n",
    "    return df\n",
    "\n",
    "def load_dept_map(path: str, sheet: str) -> pd.DataFrame:\n",
    "    \"\"\"Load dept mapping to get department_name and vertical.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        # Gracefully handle missing map file\n",
    "        return pd.DataFrame(columns=['department_id', 'department_name', 'vertical'])\n",
    "    if path.lower().endswith(\".xlsx\") or path.lower().endswith(\".xlsm\"):\n",
    "        mp = pd.read_excel(path, sheet_name=sheet, engine=\"openpyxl\")\n",
    "    else:\n",
    "        mp = pd.read_csv(path)\n",
    "    # Normalize keys\n",
    "    mp['department_id'] = mp['department_id'].astype(str).str.strip()\n",
    "    if 'department_name' in mp.columns:\n",
    "        mp['department_name'] = mp['department_name'].astype(str).str.strip()\n",
    "    if 'vertical' in mp.columns:\n",
    "        mp['vertical'] = mp['vertical'].astype(str).str.strip()\n",
    "    else:\n",
    "        mp['vertical'] = None\n",
    "    return mp[['department_id', 'department_name', 'vertical']].drop_duplicates('department_id')\n",
    "\n",
    "def load_productivity(path: str) -> pd.DataFrame:\n",
    "    \"\"\"Load agent productivity per day and compute dept-level mean tickets per agent per day.\"\"\"\n",
    "    df = pd.read_excel(path, engine=\"openpyxl\")\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['department_id'] = df['department_id'].astype(str).str.strip()\n",
    "    # Compute avg productivity per agent-day, then aggregate to department level mean\n",
    "    # If we want mean per department per day per agent:\n",
    "    #   Take mean of prod_total_model across agents & days, grouped by department.\n",
    "    df['prod_total_model'] = pd.to_numeric(df['prod_total_model'], errors='coerce')\n",
    "    prod_dept = (df\n",
    "                 .groupby('department_id', as_index=False)['prod_total_model']\n",
    "                 .mean()\n",
    "                 .rename(columns={'prod_total_model': 'avg_tickets_per_agent_day'}))\n",
    "    return prod_dept\n",
    "\n",
    "def apply_mapping(incoming: pd.DataFrame, mapping: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Merge department_name and vertical using department_id as the primary key.\"\"\"\n",
    "    merged = incoming.merge(mapping, on='department_id', how='left', suffixes=('', '_map'))\n",
    "    # Prefer mapped department_name if available\n",
    "    merged['department_name'] = np.where(merged['department_name'].isna() | (merged['department_name'] == 'None'),\n",
    "                                         merged['department_name_map'], merged['department_name'])\n",
    "    merged.drop(columns=[c for c in merged.columns if c.endswith('_map')], inplace=True, errors='ignore')\n",
    "    # Flag unmapped verticals\n",
    "    merged['vertical'] = merged['vertical'].fillna('Unmapped')\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64578b79",
   "metadata": {},
   "source": [
    "## 02 - Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45a0297c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def month_floor(dt: pd.Timestamp) -> pd.Timestamp:\n",
    "    return pd.Timestamp(year=dt.year, month=dt.month, day=1)\n",
    "\n",
    "def business_days_in_month(year: int, month: int) -> int:\n",
    "    \"\"\"Approximate working (Mon-Fri) days in given month.\"\"\"\n",
    "    rng = pd.date_range(start=pd.Timestamp(year=year, month=month, day=1),\n",
    "                        end=pd.Timestamp(year=year, month=month, day=1) + pd.offsets.MonthEnd(0),\n",
    "                        freq='D')\n",
    "    return np.sum(rng.weekday < 5)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    \"\"\"sMAPE metric robust for intermittent series.\"\"\"\n",
    "    y_true = np.array(y_true, dtype=float)\n",
    "    y_pred = np.array(y_pred, dtype=float)\n",
    "    denom = (np.abs(y_true) + np.abs(y_pred))\n",
    "    denom[denom == 0] = 1.0\n",
    "    return np.mean(2.0 * np.abs(y_pred - y_true) / denom) * 100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac18c10",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
